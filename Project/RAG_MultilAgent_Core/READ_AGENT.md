# T√ÄI LI·ªÜU B√ÄN GIAO D·ª∞ √ÅN
## RAG Multi-Agent Workflow for Enhanced RnD Assistant

## üèóÔ∏è KI·∫æN TR√öC T·ªîNG QUAN

### C·∫•u tr√∫c Workflow
```
START ‚Üí Query Classifier ‚Üí [Smart Search | Traditional Search] ‚Üí Analysis Agents ‚Üí Response Generator ‚Üí END
```

### Th√†nh ph·∫ßn ch√≠nh:
1. **RAGMultiAgentWorkflow** - Orchestrator ch√≠nh
2. **Query Classifier** - Ph√¢n lo·∫°i c√¢u h·ªèi
3. **Smart Product Search** - T√¨m ki·∫øm th√¥ng minh
4. **Analysis Agents** - C√°c agent ph√¢n t√≠ch chuy√™n bi·ªát
5. **Response Generator** - T·∫°o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng
6. **Milvus Manager** - Qu·∫£n l√Ω vector database
7. **Search Tools** - B·ªô c√¥ng c·ª• t√¨m ki·∫øm n√¢ng cao
8. **Data Processor** - X·ª≠ l√Ω v√† cache d·ªØ li·ªáu

---

## üìÅ CHI TI·∫æT C√ÅC FILE V√Ä H√ÄM

### 1. FILE: `RAGMultiAgentWorkflow` (Orchestrator ch√≠nh)

#### M·ª•c ƒë√≠ch:
ƒêi·ªÅu ph·ªëi to√†n b·ªô workflow, qu·∫£n l√Ω lu·ªìng x·ª≠ l√Ω gi·ªØa c√°c agents

#### C√°c h√†m ch√≠nh:

##### `__init__(self)`
**Ch·ª©c nƒÉng**: Kh·ªüi t·∫°o workflow v√† k·∫øt n·ªëi c√°c th√†nh ph·∫ßn
**Logic**:
- K·∫øt n·ªëi Milvus database
- Kh·ªüi t·∫°o t·∫•t c·∫£ c√°c agents
- X√¢y d·ª±ng workflow graph

##### `_build_workflow(self) -> StateGraph`
**Ch·ª©c nƒÉng**: X√¢y d·ª±ng LangGraph workflow
**Logic**:
- ƒê·ªãnh nghƒ©a c√°c nodes (classify_query, search_products, smart_search, v.v.)
- Thi·∫øt l·∫≠p routing logic:
  - START ‚Üí classify_query
  - classify_query ‚Üí [smart_search | search_products]
  - search_products ‚Üí [benchmark | market_gap | verify_idea | audience_volume]
  - T·∫•t c·∫£ ‚Üí generate_response ‚Üí END

##### `_route_after_classification(self, state) -> str`
**Ch·ª©c nƒÉng**: ƒêi·ªÅu h∆∞·ªõng sau ph√¢n lo·∫°i
**Logic**:
- N·∫øu query_type == "smart_search" ‚Üí ƒëi ƒë·∫øn smart_search
- Ng∆∞·ª£c l·∫°i ‚Üí ƒëi ƒë·∫øn search_products

##### `_route_to_analysis(self, state) -> str`
**Ch·ª©c nƒÉng**: ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn analysis agent ph√π h·ª£p
**Logic**: Tr·∫£ v·ªÅ ƒë√∫ng query_type ƒë·ªÉ route ƒë·∫øn agent t∆∞∆°ng ·ª©ng

##### `async process_query(self, query: str, input_image: str = None) -> str`
**Ch·ª©c nƒÉng**: X·ª≠ l√Ω query ch√≠nh v√† tr·∫£ v·ªÅ k·∫øt qu·∫£
**Logic**:
- T·∫°o initial_state t·ª´ query v√† image
- Ch·∫°y workflow.ainvoke()
- Tr·∫£ v·ªÅ final_answer ho·∫∑c error message

---

### 2. FILE: `query_classifier_agent.py`

#### M·ª•c ƒë√≠ch:
Ph√¢n lo·∫°i c√¢u h·ªèi c·ªßa user v√†o 5 lo·∫°i ch√≠nh ƒë·ªÉ ƒë·ªãnh h∆∞·ªõng x·ª≠ l√Ω

#### C√°c h√†m ch√≠nh:

##### `__init__(self)`
**Ch·ª©c nƒÉng**: Kh·ªüi t·∫°o classifier v·ªõi temperature=0 ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n
**Logic**: T·∫°o ChatPromptTemplate v·ªõi system prompt ƒë·ªãnh nghƒ©a 5 lo·∫°i c√¢u h·ªèi

##### `async process(self, state) -> Dict[str, Any]`
**Ch·ª©c nƒÉng**: Ph√¢n lo·∫°i query v√†o 1 trong 5 lo·∫°i
**Logic**:
- G·ª≠i query ƒë·∫øn LLM v·ªõi prompt ƒë·ªãnh nghƒ©a c√°c lo·∫°i
- Nh·∫≠n response v√† clean up
- C·∫≠p nh·∫≠t state["query_type"]
- Log k·∫øt qu·∫£ ph√¢n lo·∫°i

**5 Lo·∫°i ƒë∆∞·ª£c ph√¢n lo·∫°i**:
1. **"benchmark"**: So s√°nh ƒë·ªëi th·ªß, winning/losing ideas
2. **"market_gap"**: Kho·∫£ng tr·ªëng th·ªã tr∆∞·ªùng, c∆° h·ªôi ch∆∞a khai th√°c
3. **"verify_idea"**: X√°c minh √Ω t∆∞·ªüng, ki·ªÉm tra concept
4. **"audience_volume"**: ∆Ø·ªõc t√≠nh audience volume
5. **"smart_search"**: T√¨m ki·∫øm th√¥ng minh (m·∫∑c ƒë·ªãnh cho c√°c tr∆∞·ªùng h·ª£p kh√°c)

---

### 3. FILE: `smart_product_search_agent.py`

#### M·ª•c ƒë√≠ch:
Agent t√¨m ki·∫øm s·∫£n ph·∫©m th√¥ng minh v·ªõi kh·∫£ nƒÉng x·ª≠ l√Ω ƒëa ph∆∞∆°ng th·ª©c v√† filter extraction

#### C√°c h√†m ch√≠nh:

##### `__init__(self)`
**Ch·ª©c nƒÉng**: Kh·ªüi t·∫°o v·ªõi vision model v√† metadata mappings
**Logic**:
- Kh·ªüi t·∫°o ChatOpenAI cho vision tasks
- Load metadata mappings cho backward compatibility
- Temperature=0.2 ƒë·ªÉ c√¢n b·∫±ng t√≠nh s√°ng t·∫°o v√† nh·∫•t qu√°n

##### `async _extract_filters_with_ai(self, user_query: str) -> Dict[str, Any]`
**Ch·ª©c nƒÉng**: **CORE FUNCTION** - S·ª≠ d·ª•ng AI ƒë·ªÉ extract filters t·ª´ query
**Logic chi ti·∫øt**:

1. **T·∫°o prompt ph√¢n t√≠ch**:
   - L·∫•y th·ªùi gian hi·ªán t·∫°i
   - T·∫°o detailed prompt y√™u c·∫ßu AI nh·∫≠n di·ªán:
     - NAME_STORE: T√™n c·ª≠a h√†ng/th∆∞∆°ng hi·ªáu
     - PLATFORM: N·ªÅn t·∫£ng b√°n h√†ng
     - DATE_RANGE & TIME_FILTERS: C√°c ƒëi·ªÅu ki·ªán th·ªùi gian

2. **G·ª≠i query ƒë·∫øn AI**:
   - S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n t√≠ch query
   - AI tr·∫£ v·ªÅ JSON format v·ªõi c√°c filters

3. **Validation v√† cleanup**:
   - Parse JSON response
   - Validate t·ª´ng field (name_store, platform, date filters)
   - Check date format v·ªõi `_is_valid_date_string()`
   - **QUAN TR·ªåNG**: Lo·∫°i b·ªè date filters n·∫øu kh√¥ng c√≥ time keywords

##### `_is_valid_date_string(self, date_str: str) -> bool`
**Ch·ª©c nƒÉng**: Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa date string
**Logic**:
- Check format DD/MM/YYYY
- Validate ng√†y, th√°ng, nƒÉm h·ª£p l·ªá
- NƒÉm ph·∫£i >= 2020

##### `_contains_time_keywords(self, query: str) -> bool`
**Ch·ª©c nƒÉng**: **CRITICAL FUNCTION** - Ki·ªÉm tra query c√≥ ch·ª©a t·ª´ kh√≥a th·ªùi gian
**Logic**:
- Define comprehensive time keywords list:
  - Ng√†y th√°ng c·ª• th·ªÉ: "ng√†y", "th√°ng", "nƒÉm"
  - Th·ªùi gian t∆∞∆°ng ƒë·ªëi: "h√¥m nay", "tu·∫ßn n√†y"
  - Kho·∫£ng th·ªùi gian: "t·ª´", "ƒë·∫øn", "tr∆∞·ªõc", "sau"
  - Regex patterns cho date formats
- Tr·∫£ v·ªÅ True n·∫øu t√¨m th·∫•y b·∫•t k·ª≥ time keyword n√†o

##### `async determine_search_type(self, state) -> Dict[str, Any]`
**Ch·ª©c nƒÉng**: X√°c ƒë·ªãnh lo·∫°i t√¨m ki·∫øm v√† extract filters
**Logic**:

1. **Extract filters v·ªõi AI**:
   - G·ªçi `_extract_filters_with_ai()`
   - L∆∞u v√†o state["extracted_filters"]
   - T·∫°o filter_summary cho logging

2. **Analyze metadata** (legacy):
   - Ph√¢n t√≠ch text ƒë·ªÉ detect metadata
   - T·∫°o enriched_query v·ªõi metadata context

3. **Determine search type** (8 lo·∫°i):
   - **image_to_image**: C√≥ image + t·ª´ kh√≥a "t∆∞∆°ng t·ª±"
   - **url_to_image**: C√≥ image URL + t·ª´ kh√≥a "t∆∞∆°ng t·ª±"
   - **image_to_text**: C√≥ image + t·ª´ kh√≥a "m√¥ t·∫£"
   - **url_to_text**: C√≥ image URL + t·ª´ kh√≥a "m√¥ t·∫£"
   - **text_to_image**: T·ª´ kh√≥a "t√¨m h√¨nh"
   - **multimodal_search**: C√≥ image + text query ph·ª©c t·∫°p
   - **multimodal_url_search**: C√≥ image URL + text query
   - **text_to_text**: M·∫∑c ƒë·ªãnh

##### `async execute_smart_search(self, state) -> Dict[str, Any]`
**Ch·ª©c nƒÉng**: Th·ª±c hi·ªán t√¨m ki·∫øm theo lo·∫°i ƒë√£ x√°c ƒë·ªãnh
**Logic**:

1. **L·∫•y search parameters**:
   - search_type t·ª´ state
   - enriched_query (c√≥ metadata)
   - **filters t·ª´ AI extraction**

2. **Execute search theo type**:
   - **text_to_image**: `search_by_description_tool` v·ªõi filters
   - **image_to_image**: `search_by_image_tool` v·ªõi filters
   - **url_to_image**: Download image ‚Üí convert base64 ‚Üí search
   - **image_to_text**: Convert image to text ‚Üí search by description
   - **multimodal_search**: `search_multimodal_tool` v·ªõi text + image + filters
   - **text_to_text**: `search_by_description_tool` v·ªõi filters

3. **Error handling**:
   - Try-catch cho c√°c operations c√≥ th·ªÉ fail
   - Tr·∫£ v·ªÅ error messages r√µ r√†ng

##### `async _image_to_text_description(self, image_base64: str) -> str`
**Ch·ª©c nƒÉng**: Chuy·ªÉn ƒë·ªïi image th√†nh text description
**Logic**:
- S·ª≠ d·ª•ng vision model v·ªõi prompt ti·∫øng Vi·ªát
- T·∫°o HumanMessage v·ªõi image_url format
- Tr·∫£ v·ªÅ detailed description ho·∫∑c error message

##### Helper Functions:

##### `_analyze_text_metadata(self, text: str) -> Dict[str, List[str]]`
**Ch·ª©c nƒÉng**: Legacy function - ph√¢n t√≠ch metadata t·ª´ text
**Logic**: S·ª≠ d·ª•ng predefined mappings ƒë·ªÉ detect main_subject, product_type, recipient

##### `_is_image_url(self, text: str) -> bool`
**Ch·ª©c nƒÉng**: Ki·ªÉm tra text c√≥ ph·∫£i image URL
**Logic**: Check URL pattern + image extensions

##### `_is_base64_image(self, text: str) -> bool`
**Ch·ª©c nƒÉng**: Ki·ªÉm tra text c√≥ ph·∫£i base64 image
**Logic**: Check data:image prefix ho·∫∑c base64 pattern

---

### 4. FILE: `base_agent.py`

#### M·ª•c ƒë√≠ch:
Base class cho t·∫•t c·∫£ agents, cung c·∫•p common functionality

#### C√°c h√†m ch√≠nh:

##### `__init__(self, temperature: float = 0.3)`
**Ch·ª©c nƒÉng**: Kh·ªüi t·∫°o base agent v·ªõi LLM
**Logic**: T·∫°o ChatOpenAI instance v·ªõi API key v√† temperature

##### `_safe_int_convert(self, value) -> int`
**Ch·ª©c nƒÉng**: Chuy·ªÉn ƒë·ªïi value th√†nh integer m·ªôt c√°ch an to√†n
**Logic**:
- Handle string v·ªõi d·∫•u ph·∫©y
- Return 0 n·∫øu conversion fails
- D√πng cho x·ª≠ l√Ω engagement numbers

##### `_calculate_engagement_score(self, product: Dict) -> int`
**Ch·ª©c nƒÉng**: T√≠nh engagement score cho product
**Logic**:
- likes + comments * 5 + shares * 10
- Weighted scoring ƒë·ªÉ ∆∞u ti√™n interactions c√≥ gi√° tr·ªã cao

---

### 5. FILE: `response_generator_agent.py`

#### M·ª•c ƒë√≠ch:
Agent cu·ªëi c√πng trong workflow, t·∫°o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng d·ª±a tr√™n k·∫øt qu·∫£ t·ª´ c√°c analysis agents

#### C√°c h√†m ch√≠nh:

##### `__init__(self)`
**Ch·ª©c nƒÉng**: Kh·ªüi t·∫°o v·ªõi temperature=0.3 ƒë·ªÉ c√¢n b·∫±ng creativity v√† consistency
**Logic**: Inherit t·ª´ BaseAgent, s·ª≠ d·ª•ng temperature moderate cho text generation

##### `async process(self, state) -> Dict[str, Any]`
**Ch·ª©c nƒÉng**: **MAIN DISPATCHER** - ƒêi·ªÅu ph·ªëi t·∫°o response theo query_type
**Logic**:
- L·∫•y query_type t·ª´ state
- Route ƒë·∫øn ƒë√∫ng response generator:
  - "smart_search" ‚Üí `_generate_smart_search_response()`
  - "benchmark" ‚Üí `_generate_benchmark_response()`
  - "market_gap" ‚Üí `_generate_market_gap_response()`
  - "verify_idea" ‚Üí `_generate_verify_idea_response()`
  - "audience_volume" ‚Üí `_generate_audience_volume_response()`
- C·∫≠p nh·∫≠t state["final_answer"] v√† log message

##### `_generate_smart_search_response(self, state) -> str`
**Ch·ª©c nƒÉng**: T·∫°o response cho smart search queries
**Logic chi ti·∫øt**:

1. **Header v√† Metadata**:
   - L·∫•y search_type, results, query t·ª´ state
   - T·∫°o title v·ªõi search type ƒë∆∞·ª£c format

2. **Error Handling**:
   - Check empty results ho·∫∑c error trong results
   - Return early v·ªõi error message n·∫øu c√≥ l·ªói

3. **Overview Section**:
   - S·ªë l∆∞·ª£ng s·∫£n ph·∫©m t√¨m th·∫•y
   - Confirm c√≥ image URLs

4. **Results Display** (top 100):
   - Loop qua results ƒë·ªÉ hi·ªÉn th·ªã:
     - Store name
     - **Image URL** (key feature)
     - Description (truncated)
     - Engagement metrics
     - Similarity score
     - Platform v√† date

5. **Specialized Insights**:
   - Th√™m image analysis insights cho image search types
   - Include search_description n·∫øu c√≥ (t·ª´ image-to-text)

6. **Next Steps**:
   - Actionable recommendations
   - Emphasis on image URLs usage

##### `_generate_benchmark_response(self, state) -> str`
**Ch·ª©c nƒÉng**: T·∫°o response cho benchmark analysis
**Logic chi ti·∫øt**:

1. **Performance Overview**:
   - Total products analyzed
   - Aggregate engagement metrics
   - Average engagement calculation

2. **Winners vs Losers Analysis**:
   - Count v√† comparison
   - Identify top performers vs underperformers

3. **Winning Products Display**:
   - Top 100 winning products v·ªõi:
     - Engagement score calculation
     - **Image URLs** for visual analysis
     - Store info v√† platform

4. **Success Factors Analysis**:
   - Key success factors t·ª´ analysis
   - Metadata insights breakdown:
     - Popular themes
     - Target audiences
     - Platform distribution

5. **Actionable Recommendations**:
   - Market signal interpretation
   - Strategy recommendations based on win/loss ratio
   - Visual analysis recommendations

##### `_generate_market_gap_response(self, state) -> str`
**Ch·ª©c nƒÉng**: T·∫°o response cho market gap analysis
**Logic chi ti·∫øt**:

1. **Current Market Landscape**:
   - Popular themes analysis
   - Main target audiences
   - Popular occasions

2. **Identified Gaps**:
   - Audience gaps (underserved segments)
   - Occasion gaps (missed opportunities)
   - Theme gaps (underdeveloped areas)

3. **Market Opportunities**:
   - List opportunities t·ª´ analysis
   - Underserved segments identification

4. **Competitor Weaknesses**:
   - Areas where competitors are weak
   - Exploitation opportunities

5. **Action Plan**:
   - 5-step strategic plan
   - Multi-platform recommendations
   - Visual differentiation strategy

##### `_generate_verify_idea_response(self, state) -> str`
**Ch·ª©c nƒÉng**: T·∫°o response cho idea verification
**Logic chi ti·∫øt**:

1. **Verification Results**:
   - Similar products count
   - Market validation status
   - Success rate percentage

2. **Viability Assessment**:
   - 5-tier viability scale:
     - high_viability
     - moderate_viability
     - low_viability
     - high_risk
     - untested_concept
   - Color-coded messaging system

3. **Performance Breakdown**:
   - High/medium/low performers count
   - Success distribution analysis

4. **Similar Concepts Display**:
   - Top 10 similar concepts v·ªõi:
     - Similarity scores
     - **Image URLs** for comparison
     - Engagement analysis
     - Platform performance

5. **Pattern Analysis**:
   - Best performing platform identification
   - Common success themes
   - Performance patterns

6. **Strategic Recommendations**:
   - Next steps based on viability
   - Visual analysis guidance
   - A/B testing suggestions

##### `_generate_audience_volume_response(self, state) -> str`
**Ch·ª©c nƒÉng**: T·∫°o response cho audience volume estimation
**Logic chi ti·∫øt**:

1. **Volume Estimation**:
   - 3-tier estimate system:
     - Conservative estimate
     - Recommended estimate (primary)
     - Optimistic estimate
   - Sample size v√† total engagement

2. **Platform-wise Analysis**:
   - Sort platforms by engagement
   - Display cho m·ªói platform:
     - Product count
     - Average engagement
     - Estimated audience per platform

3. **Trend Analysis**:
   - 4 trend directions:
     - increasing (growing)
     - decreasing (declining)
     - stable (consistent)
     - insufficient_data
   - Data span analysis

4. **Confidence Level**:
   - 5-tier confidence system
   - Color-coded reliability indicators

5. **Strategic Recommendations**:
   - Strategy based on volume size:
     - >10K: Mass market approach
     - >1K: Targeted marketing
     - <1K: Niche strategy
   - Pricing v√† positioning guidance

### Helper Functions trong Response Generator:

##### `_calculate_engagement_score(self, product) -> int`
**Ch·ª©c nƒÉng**: Inherited t·ª´ BaseAgent, t√≠nh engagement score
**Logic**: likes + comments*5 + shares*10 (weighted scoring)

---

### 6. FILE: `rag_multi_agent_workflow.py` (CORE ORCHESTRATOR)

#### M·ª•c ƒë√≠ch:
**TRUNG T√ÇM ƒêI·ªÄU PH·ªêI** - Qu·∫£n l√Ω to√†n b·ªô workflow v√† k·∫øt n·ªëi c√°c agents

#### C√°c h√†m ch√≠nh:

##### `__init__(self)`
**Ch·ª©c nƒÉng**: **SYSTEM INITIALIZATION** - Kh·ªüi t·∫°o to√†n b·ªô h·ªá th·ªëng
**Logic**:
1. **Database Connection**: K·∫øt n·ªëi Milvus vector database
2. **Agent Initialization**: Kh·ªüi t·∫°o t·∫•t c·∫£ 8 agents:
   - classifier_agent
   - search_agent
   - smart_search_agent
   - benchmark_agent
   - market_gap_agent
   - verify_idea_agent
   - audience_volume_agent
   - response_generator
3. **Workflow Build**: G·ªçi _build_workflow() ƒë·ªÉ t·∫°o StateGraph

##### `_build_workflow(self) -> StateGraph`
**Ch·ª©c nƒÉng**: **CORE WORKFLOW ARCHITECT** - X√¢y d·ª±ng LangGraph workflow
**Logic chi ti·∫øt**:

1. **Create StateGraph**:
   - Initialize v·ªõi AgentState schema

2. **Add Nodes** (8 nodes):
   - classify_query: Ph√¢n lo·∫°i query
   - search_products: Traditional search
   - smart_search: Smart/multimodal search
   - 4 analysis nodes: benchmark, market_gap, verify_idea, audience_volume
   - generate_response: Final response generation

3. **Define Edges**:
   - **Linear Flow**: START ‚Üí classify_query
   - **Conditional Routing 1**: classify_query ‚Üí [smart_search | search_products]
   - **Direct Path**: smart_search ‚Üí generate_response
   - **Conditional Routing 2**: search_products ‚Üí [4 analysis types]
   - **Convergence**: All analysis ‚Üí generate_response ‚Üí END

4. **Compile Workflow**: T·∫°o executable workflow

##### `_route_after_classification(self, state) -> str`
**Ch·ª©c nƒÉng**: **ROUTING LOGIC 1** - ƒêi·ªÅu h∆∞·ªõng sau classification
**Logic**:
- Input: state v·ªõi query_type
- Logic: N·∫øu query_type == "smart_search" ‚Üí route to smart_search
- Else ‚Üí route to traditional search ("other")
- Return: routing key

##### `_route_to_analysis(self, state) -> str`
**Ch·ª©c nƒÉng**: **ROUTING LOGIC 2** - ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn analysis agent
**Logic**:
- Input: state v·ªõi query_type
- Return: exact query_type ƒë·ªÉ route ƒë·∫øn ƒë√∫ng analysis agent
- Direct mapping: query_type = node_name

##### **NODE WRAPPER FUNCTIONS** (8 functions):

##### `async _classify_query(self, state) -> AgentState`
**Ch·ª©c nƒÉng**: Node wrapper cho query classification
**Logic**: G·ªçi classifier_agent.process(state)

##### `async _search_products(self, state) -> AgentState`
**Ch·ª©c nƒÉng**: Node wrapper cho traditional product search
**Logic**: G·ªçi search_agent.process(state)

##### `async _smart_search(self, state) -> AgentState`
**Ch·ª©c nƒÉng**: Node wrapper cho smart/multimodal search
**Logic**: G·ªçi smart_search_agent.process(state)

##### `async _benchmark_analysis(self, state) -> AgentState`
**Ch·ª©c nƒÉng**: Node wrapper cho benchmark analysis
**Logic**: G·ªçi benchmark_agent.process(state)

##### `async _market_gap_analysis(self, state) -> AgentState`
**Ch·ª©c nƒÉng**: Node wrapper cho market gap analysis
**Logic**: G·ªçi market_gap_agent.process(state)

##### `async _verify_idea_analysis(self, state) -> AgentState`
**Ch·ª©c nƒÉng**: Node wrapper cho idea verification
**Logic**: G·ªçi verify_idea_agent.process(state)

##### `async _audience_volume_analysis(self, state) -> AgentState`
**Ch·ª©c nƒÉng**: Node wrapper cho audience volume analysis
**Logic**: G·ªçi audience_volume_agent.process(state)

##### `async _generate_response(self, state) -> AgentState`
**Ch·ª©c nƒÉng**: Node wrapper cho response generation
**Logic**: G·ªçi response_generator.process(state)

##### **PUBLIC INTERFACE FUNCTIONS**:

##### `async process_query(self, query: str, input_image: str = None) -> str`
**Ch·ª©c nƒÉng**: **MAIN PUBLIC API** - Process user query
**Logic**:
1. **Create Initial State**: G·ªçi create_initial_state(query, input_image)
2. **Execute Workflow**: await self.workflow.ainvoke(initial_state)
3. **Extract Result**: Return final_state["final_answer"]
4. **Error Handling**: Try-catch v·ªõi Vietnamese error message

##### `get_workflow_graph(self)`
**Ch·ª©c nƒÉng**: Visualization support - tr·∫£ v·ªÅ workflow graph
**Logic**: Return compiled workflow cho debugging/visualization

##### `async process_query_with_state(self, query: str, input_image: str = None) -> Dict[str, Any]`
**Ch·ª©c nƒÉng**: **DEBUG API** - Process query v√† return full state
**Logic**:
- Similar to process_query nh∆∞ng return to√†n b·ªô final_state
- D√πng cho debugging v√† inspection
- Include error trong response thay v√¨ raise exception

---

### 7. FILE: `chatbot.py` (USER INTERFACE)

#### M·ª•c ƒë√≠ch:
**FRONT-END INTERFACE** - Cung c·∫•p giao di·ªán chat cho user t∆∞∆°ng t√°c v·ªõi h·ªá th·ªëng

#### C√°c h√†m ch√≠nh:

##### `__init__(self)`
**Ch·ª©c nƒÉng**: Initialize chatbot instance
**Logic**:
- T·∫°o RAGMultiAgentWorkflow instance
- Print welcome message v·ªõi Vietnamese

##### `async chat(self, user_input: str, image_base64: Optional[str] = None) -> str`
**Ch·ª©c nƒÉng**: **CORE CHAT FUNCTION** - Main chat interface
**Logic**:
1. **Input Validation**: Check empty input
2. **Logging**: Print processing status v·ªõi emoji
3. **Image Detection**: Check v√† log n·∫øu c√≥ image
4. **Workflow Execution**: await self.workflow.process_query()
5. **Return Response**: Return formatted response

##### `run_interactive(self)`
**Ch·ª©c nƒÉng**: **INTERACTIVE SESSION** - Run continuous chat session
**Logic chi ti·∫øt**:

1. **Welcome Banner**:
   - System description
   - Feature list (5 main functions)
   - Smart search capabilities
   - Special commands

2. **Main Loop**:
   - **Input Handling**: input() v·ªõi prompt
   - **Exit Commands**: 'quit', 'exit', 'bye'
   - **Empty Input**: Skip processing

3. **Image Handling**:
   - **Command Detection**: 'image:' prefix
   - **File Loading**: 
     - Extract path t·ª´ command
     - Read binary file
     - Convert to base64
     - Get additional query v·ªÅ image
   - **Error Handling**: Try-catch cho file operations

4. **Query Processing**:
   - **Execute**: asyncio.run(self.chat())
   - **Display**: Print formatted response
   - **Error Handling**: Catch v√† display exceptions

5. **Session Management**:
   - **Interrupt Handling**: KeyboardInterrupt (Ctrl+C)
   - **Graceful Exit**: Thank you message
   - **Error Recovery**: Continue session sau errors

### Special Features trong Chatbot:

##### **Image Input Support**:
- Command format: 'image:[path]'
- Automatic base64 conversion
- Secondary prompt for image-related query
- Error handling cho invalid paths

##### **Multi-language Support**:
- Vietnamese interface
- English/Vietnamese mixed commands
- Localized error messages

##### **Interactive Features**:
- Rich console output v·ªõi emoji
- Progress indicators
- Clear command structure
- Help information

---

### 8. FILE: `milvus_manager.py` (DATABASE LAYER)

#### M·ª•c ƒë√≠ch:
**VECTOR DATABASE INTERFACE** - Qu·∫£n l√Ω t·∫•t c·∫£ operations v·ªõi Milvus vector database

#### C√°c h√†m ch√≠nh:

##### `__init__(self)`
**Ch·ª©c nƒÉng**: **SYSTEM INITIALIZATION** - Kh·ªüi t·∫°o k·∫øt n·ªëi v√† embedding service
**Logic**:
- K·∫øt n·ªëi Milvus database (localhost:19530)
- Kh·ªüi t·∫°o embedding service
- Load collection information
- Setup image processing capabilities

##### `connect(self) -> bool`
**Ch·ª©c nƒÉng**: Thi·∫øt l·∫≠p k·∫øt n·ªëi ƒë·∫øn Milvus server
**Logic**:
- Connect v·ªõi default configuration
- Error handling cho connection failures
- Return True/False based on success

##### `search_by_text_description(self, description: str, top_k: int = 100, filters: Optional[Dict] = None) -> List[Dict]`
**Ch·ª©c nƒÉng**: **TEXT SEARCH CORE** - T√¨m ki·∫øm s·∫£n ph·∫©m b·∫±ng text description
**Logic**:
1. **Vector Generation**: Convert text description th√†nh embedding vector
2. **Filter Construction**: Build Milvus filter expressions t·ª´ filters dict
3. **Search Execution**: Execute vector similarity search
4. **Results Processing**: Convert Milvus results th√†nh standard format
5. **Error Handling**: Graceful error handling v·ªõi fallback

##### `search_by_image_vector(self, image_vector: List[float], top_k: int = 100, filters: Optional[Dict] = None) -> List[Dict]`
**Ch·ª©c nƒÉng**: **IMAGE VECTOR SEARCH** - T√¨m ki·∫øm b·∫±ng image vector
**Logic**:
1. **Vector Validation**: Check image vector format v√† dimensions
2. **Filter Application**: Apply date/platform/store filters
3. **Similarity Search**: Execute vector search trong image vector field
4. **Result Ranking**: Sort by similarity score
5. **Metadata Enrichment**: Add additional product metadata

##### `search_by_image_url(self, image_url: str, top_k: int = 100, filters: Optional[Dict] = None) -> List[Dict]`
**Ch·ª©c nƒÉng**: **URL-BASED IMAGE SEARCH** - T√¨m ki·∫øm b·∫±ng image URL
**Logic**:
1. **URL Processing**: Download image t·ª´ URL
2. **Image Conversion**: Convert th√†nh appropriate format
3. **Vector Generation**: Extract image features th√†nh vector
4. **Search Delegation**: Call search_by_image_vector v·ªõi generated vector
5. **Cleanup**: Clean up temporary files

##### `search_multimodal(self, text: str = "", image_url: str = "", top_k: int = 100, filters: Optional[Dict] = None) -> List[Dict]`
**Ch·ª©c nƒÉng**: **MULTIMODAL SEARCH ENGINE** - Combined text + image search
**Logic**:
1. **Input Processing**: Process both text v√† image inputs
2. **Vector Generation**: Create combined multimodal vectors
3. **Weight Balancing**: Balance text vs image similarity weights
4. **Hybrid Search**: Execute both text v√† image searches
5. **Result Fusion**: Combine v√† rank results t·ª´ both modalities
6. **Deduplication**: Remove duplicate results

##### `get_image_vector(self, image: PIL.Image) -> List[float]`
**Ch·ª©c nƒÉng**: **IMAGE FEATURE EXTRACTION** - Convert PIL Image th√†nh vector
**Logic**:
- Use embedding service ƒë·ªÉ extract image features
- Normalize vector dimensions
- Handle various image formats
- Error handling cho corrupted images

##### `get_query_vector(self, query: str) -> List[float]`
**Ch·ª©c nƒÉng**: **TEXT EMBEDDING** - Convert text query th√†nh embedding vector
**Logic**:
- Use text embedding model
- Normalize vector length
- Handle multilingual text (Vietnamese/English)
- Cache frequently used queries

##### **BATCH OPERATIONS**:

##### `batch_search_texts(self, descriptions: List[str], top_k: int = 100) -> List[List[Dict]]`
**Ch·ª©c nƒÉng**: **BATCH TEXT SEARCH** - Process multiple text queries simultaneously
**Logic**:
1. **Batch Vectorization**: Convert all descriptions th√†nh vectors c√πng l√∫c
2. **Parallel Search**: Execute multiple searches concurrently
3. **Result Collection**: Collect results t·ª´ all searches
4. **Memory Management**: Efficient memory usage cho large batches

##### `batch_search_images(self, image_urls: List[str], top_k: int = 100, filters: Optional[Dict] = None) -> List[List[Dict]]`
**Ch·ª©c nƒÉng**: **BATCH IMAGE SEARCH** - Process multiple image URLs
**Logic**:
1. **URL Validation**: Validate all image URLs
2. **Concurrent Download**: Download images in parallel
3. **Batch Vector Extraction**: Extract features t·ª´ all images
4. **Parallel Search**: Execute searches concurrently
5. **Resource Cleanup**: Clean up all temporary files

##### **UTILITY FUNCTIONS**:

##### `get_model_info(self) -> Dict[str, Any]`
**Ch·ª©c nƒÉng**: Return information v·ªÅ embedding models being used
**Logic**:
- Model names v√† versions
- Vector dimensions
- Performance metrics
- Configuration details

##### `health_check(self) -> Dict[str, Any]`
**Ch·ª©c nƒÉng**: **SYSTEM HEALTH CHECK** - Ki·ªÉm tra t√¨nh tr·∫°ng database v√† connections
**Logic**:
1. **Connection Test**: Test Milvus connection status
2. **Collection Status**: Verify collection existence v√† accessibility
3. **Performance Metrics**: Check query response times
4. **Resource Usage**: Monitor memory v√† CPU usage
5. **Error Detection**: Identify potential issues

##### **FILTER CONSTRUCTION**:

##### `_build_filter_expression(self, filters: Dict[str, Any]) -> str`
**Ch·ª©c nƒÉng**: **FILTER BUILDER** - Convert filter dict th√†nh Milvus expression
**Logic**:
1. **Date Range Filters**: 
   - Handle DD/MM/YYYY format
   - Convert th√†nh Milvus timestamp expressions
   - Support date_start v√† date_end
2. **Platform Filters**: Match exact platform names
3. **Store Name Filters**: Support partial matching v·ªõi LIKE operator
4. **Logical Operators**: Combine multiple filters v·ªõi AND/OR
5. **Expression Validation**: Validate syntax before execution

---

### 9. FILE: `search_tools.py` (ADVANCED SEARCH TOOLKIT)

#### M·ª•c ƒë√≠ch:
**COMPREHENSIVE SEARCH TOOLKIT** - B·ªô c√¥ng c·ª• t√¨m ki·∫øm n√¢ng cao v·ªõi AI-powered processing

#### C√°c Class v√† Tool ch√≠nh:

##### **CLASS: SearchQueryProcessor**
**M·ª•c ƒë√≠ch**: Advanced query processor v·ªõi Vietnamese-English mapping v√† attribute extraction

##### `CATEGORY_MAPPINGS` (Static Dictionary)
**Ch·ª©c nƒÉng**: **MULTILINGUAL MAPPING** - Vietnamese-English product category mapping
**N·ªôi dung**:
- Product types: 'm≈©' ‚Üí ['cap', 'hat'], 'n√≥n' ‚Üí ['cap', 'hat']
- Objects: 'b·∫£ng' ‚Üí ['plaque', 'desk plaque'], 'bi·ªÉn' ‚Üí ['plaque']
- Occasions: 'sinh nh·∫≠t' ‚Üí ['birthday'], 'th·ªÉ thao' ‚Üí ['sports']
- Recipients: 'con g√°i' ‚Üí ['daughter'], 'con trai' ‚Üí ['son']
- Relationships: 'cha' ‚Üí ['father', 'dad'], 'm·∫π' ‚Üí ['mother', 'mom']

##### `ATTRIBUTE_HIERARCHY` (Static Dictionary)
**Ch·ª©c nƒÉng**: **STRUCTURED ATTRIBUTES** - Hierarchical attribute classification
**Structure**:
- **product_type**: ['cap', 'hat', 'desk plaque', 'plaque']
- **subject**: ['basketball team logo', 'mascot', 'logo'] 
- **recipient**: ['daughter', 'son', 'kids', 'children']
- **giver**: ['from mother', 'from father', 'from wife', 'from husband']
- **occasion**: ['birthday', 'christmas', 'father\'s day', 'mother\'s day']
- **theme**: ['basketball', 'sports']
- **colors**: ['orange', 'blue', 'pink', 'red', 'green', 'yellow']
- **style**: ['elegant', 'sports theme', 'sentimental', 'energetic']
- **text_content**: ['champs', 'okc', 'thunder', 'oklahoma city thunder']
- **brand_level**: ['tm resemblance']

##### `extract_key_attributes(cls, description: str) -> Dict[str, List[str]]`
**Ch·ª©c nƒÉng**: **ATTRIBUTE EXTRACTION** - Extract structured attributes t·ª´ description
**Logic**:
1. **Text Preprocessing**: Convert description to lowercase
2. **Pattern Matching**: Loop through ATTRIBUTE_HIERARCHY
3. **Keyword Detection**: Find matching keywords trong description
4. **Classification**: Group keywords theo categories
5. **Return Structure**: Dictionary v·ªõi category ‚Üí list of found attributes

##### `expand_query_terms(cls, query: str) -> List[str]`
**Ch·ª©c nƒÉng**: **QUERY EXPANSION** - Expand query v·ªõi synonyms v√† related terms
**Logic**:
1. **Base Terms**: Start v·ªõi original query
2. **Vietnamese-English Mapping**: Add English equivalents cho Vietnamese terms
3. **Attribute-based Expansion**: Add related terms t·ª´ same categories
4. **Deduplication**: Remove duplicate terms
5. **Limitation**: Limit to reasonable number of terms ƒë·ªÉ avoid noise

##### `create_structured_query(cls, query: str) -> str`
**Ch·ª©c nƒÉng**: **QUERY STRUCTURING** - Create priority-based structured query
**Logic**:
1. **Attribute Extraction**: Extract attributes t·ª´ original query
2. **Priority Organization**:
   - **High Priority**: Product type v√† main subject
   - **Medium Priority**: Recipient v√† occasion
   - **Lower Priority**: Style, colors, themes
3. **Query Construction**: Build structured query v·ªõi priority sections
4. **Expansion Integration**: Add expanded terms cho better matching
5. **Format**: "Original | Product: X | Subject: Y | For: Z | Related: terms"

##### `score_results(cls, results: List[Dict], original_query: str) -> List[Dict]`
**Ch·ª©c nƒÉng**: **INTELLIGENT RESULT SCORING** - Post-process v√† score results
**Logic**:
1. **Query Analysis**: Extract attributes t·ª´ original query
2. **Result Analysis**: Extract attributes t·ª´ each result
3. **Attribute Matching**: Calculate overlap gi·ªØa query v√† result attributes
4. **Match Score Calculation**: 
   - Count matched attributes per category
   - Calculate percentage match score
5. **Combined Scoring**: 
   - 30% attribute match score
   - 70% original similarity score
6. **Result Ranking**: Sort by combined score
7. **Metadata Addition**: Add match details ƒë·ªÉ debugging

#### **SEARCH TOOLS** (LangChain Tools):

##### `@tool search_by_description_tool(description, top_k, use_enhanced_processing, filters)`
**Ch·ª©c nƒÉng**: **ENHANCED TEXT SEARCH** - Advanced text search v·ªõi processing options
**Logic**:
1. **Processing Decision**: Check use_enhanced_processing flag
2. **Enhanced Path**:
   - Create SearchQueryProcessor instance
   - Generate structured query v·ªõi create_structured_query()
   - Execute search v·ªõi enhanced query
   - Score results v·ªõi intelligent scoring
   - Return top_k results
3. **Standard Path**: Direct milvus search without enhancement
4. **Error Handling**: Comprehensive error catching v√† logging

##### `@tool multi_strategy_search_tool(query, strategies, top_k, filters)`
**Ch·ª©c nƒÉng**: **MULTI-STRATEGY SEARCH** - Execute multiple search strategies simultaneously
**Logic**:
1. **Strategy Definition**: Support 4 strategies:
   - **exact**: Direct query search
   - **expanded**: Search v·ªõi expanded terms
   - **structured**: Search v·ªõi structured query
   - **fuzzy**: Search v·ªõi extracted attributes only
2. **Parallel Execution**: Execute all selected strategies
3. **Result Collection**: Collect results t·ª´ all strategies
4. **Deduplication**: Remove duplicate results across strategies
5. **Strategy Tagging**: Tag each result v·ªõi source strategy
6. **Intelligent Ranking**: Apply scoring across all results
7. **Analytics**: Return strategy analysis v√† query breakdown

##### `@tool smart_product_search_tool(query, context, top_k, filters)`
**Ch·ª©c nƒÉng**: **CONTEXT-AWARE SEARCH** - Search v·ªõi user context v√† preferences
**Logic**:
1. **Query Enhancement**: Enhance query v·ªõi context information:
   - **user_preferences**: Add preference terms to query
   - **previous_searches**: Consider search history
   - **filter_preferences**: Apply user's default filters
2. **Context Integration**: Build enhanced query t·ª´ all context sources
3. **Enhanced Search**: Use enhanced description search
4. **Post-filtering**: Apply must_have_attributes t·ª´ context
5. **Result Validation**: Ensure results match required attributes

##### `@tool search_by_image_tool(image_base64, top_k, filters)`
**Ch·ª©c nƒÉng**: **IMAGE SIMILARITY SEARCH** - Find products similar to input image
**Logic**:
1. **Image Decoding**: Decode base64 th√†nh binary image data
2. **Image Loading**: Load v·ªõi PIL Image
3. **Vector Extraction**: Convert image th√†nh feature vector
4. **Database Search**: Execute vector similarity search
5. **Filter Application**: Apply date/platform/store filters
6. **Error Handling**: Handle corrupted images v√† encoding errors

##### `@tool search_by_image_url_tool(image_url, top_k, filters)`
**Ch·ª©c nƒÉng**: **URL IMAGE SEARCH** - Search using image t·ª´ URL
**Logic**:
1. **URL Validation**: Validate image URL format
2. **Image Download**: Download image t·ª´ URL
3. **Format Conversion**: Convert to appropriate format
4. **Search Delegation**: Call milvus_manager.search_by_image_url
5. **Resource Cleanup**: Clean up downloaded files

##### `@tool search_multimodal_tool(text, image_base64, top_k, filters)`
**Ch·ª©c nƒÉng**: **MULTIMODAL SEARCH ENGINE** - Combined text + image search
**Logic**:
1. **Input Processing**: Handle both text v√† image inputs
2. **Image Handling**: Create temporary file t·ª´ base64
3. **Text Enhancement**: Apply query processing to text
4. **Multimodal Execution**: Call milvus_manager.search_multimodal
5. **Resource Management**: Clean up temporary files
6. **Error Recovery**: Handle partial failures gracefully

##### `@tool search_products_with_filters_tool(query, filters, top_k)`
**Ch·ª©c nƒÉng**: **FILTERED PRODUCT SEARCH** - Search v·ªõi comprehensive filtering
**Logic**:
1. **Query Enhancement**: Apply structured query processing
2. **Vector Generation**: Convert enhanced query th√†nh vector
3. **Filtered Search**: Execute search v·ªõi all provided filters
4. **Direct Database Call**: Call milvus_manager.search_products

#### **BATCH PROCESSING TOOLS**:

##### `@tool batch_search_descriptions_tool(descriptions, top_k)`
**Ch·ª©c nƒÉng**: **BATCH TEXT SEARCH** - Process multiple descriptions simultaneously
**Logic**:
1. **Batch Enhancement**: Apply structured processing to all descriptions
2. **Batch Execution**: Call milvus_manager.batch_search_texts
3. **Parallel Processing**: Process multiple queries concurrently
4. **Result Organization**: Return results trong same order as input

##### `@tool batch_search_images_tool(image_urls, top_k, filters)`
**Ch·ª©c nƒÉng**: **BATCH IMAGE SEARCH** - Process multiple images at once
**Logic**:
1. **URL Validation**: Validate all image URLs
2. **Batch Processing**: Process multiple images simultaneously
3. **Filter Application**: Apply consistent filters across all searches
4. **Error Isolation**: Handle individual failures without affecting batch

#### **ANALYSIS TOOLS**:

##### `@tool similarity_comparison_tool(text1, text2, image1_base64, image2_base64, filters)`
**Ch·ª©c nƒÉng**: **PRODUCT SIMILARITY ANALYSIS** - Deep comparison between two products
**Logic**:
1. **Multimodal Processing**: Handle both text v√† image inputs
2. **Image File Management**: Create temporary files cho images
3. **Enhanced Text Processing**: Apply structured processing to both texts
4. **Multimodal Embedding**: Generate combined embeddings cho both products
5. **Similarity Calculation**:
   - **Text Similarity**: Cosine similarity between text vectors
   - **Image Similarity**: Cosine similarity between image vectors (if both images provided)
   - **Overall Similarity**: Weighted average (50% text, 50% image)
6. **Attribute Analysis**: Compare extracted attributes between products:
   - **Category-wise Comparison**: Analyze each attribute category
   - **Common Attributes**: List shared characteristics
   - **Unique Attributes**: List differences
   - **Similarity Scores**: Calculate Jaccard similarity cho each category
7. **Interpretation**: Provide human-readable similarity levels
8. **Resource Cleanup**: Clean up all temporary files

##### `@tool get_embedding_info_tool()`
**Ch·ª©c nƒÉng**: **MODEL INFORMATION** - Get embedding model details
**Logic**: Return milvus_manager.get_model_info()

##### `@tool find_trend_clusters_tool(descriptions, similarity_threshold, filters)`
**Ch·ª©c nƒÉng**: **TREND CLUSTERING** - Group similar products into clusters
**Logic**:
1. **Text Enhancement**: Apply structured processing to all descriptions
2. **Batch Embedding**: Generate embeddings cho all descriptions
3. **Clustering Algorithm**:
   - **Similarity Matrix**: Calculate pairwise similarities
   - **Threshold Clustering**: Group items above similarity threshold
   - **Cluster Formation**: Create non-overlapping clusters
4. **Cluster Analysis**:
   - **Attribute Extraction**: Extract attributes cho each cluster
   - **Dominant Theme**: Identify main theme cho each cluster
   - **Common Attributes**: Find shared characteristics
5. **Trend Analysis**: 
   - **Cluster Sizes**: Analyze cluster distribution
   - **Theme Distribution**: Identify popular themes
   - **Market Insights**: Provide trend insights
6. **Result Structure**: Return comprehensive cluster information

---

### 10. FILE: `data_processor.py` (DATA MANAGEMENT LAYER)

#### M·ª•c ƒë√≠ch:
**HIGH-PERFORMANCE DATA PROCESSING** - Streamlit-optimized data loading v·ªõi advanced caching

#### C√°c h√†m ch√≠nh:

##### **CONNECTION MANAGEMENT**:

##### `@st.cache_resource get_milvus_connection()`
**Ch·ª©c nƒÉng**: **CACHED CONNECTION** - Singleton Milvus connection v·ªõi caching
**Logic**:
- **Resource Caching**: Use Streamlit's cache_resource cho singleton pattern
- **Connection Setup**: Connect to localhost:19530
- **Error Handling**: Graceful error handling v·ªõi user feedback
- **Return Status**: Boolean success indicator

##### `connect_to_milvus()`
**Ch·ª©c nƒÉng**: **CONNECTION WRAPPER** - Wrapper function cho cached connection
**Logic**: Simple wrapper ƒë·ªÉ get_milvus_connection() cho consistency

#### **DATA LOADING WITH ADVANCED CACHING**:

##### `@st.cache_data(ttl=7200) load_collection_data()`
**Ch·ª©c nƒÉng**: **ID-BASED PAGINATION LOADER** - Load collection data v·ªõi intelligent pagination
**Logic chi ti·∫øt**:

1. **Collection Validation**:
   - Check collection existence v·ªõi utility.has_collection()
   - Load collection v√† get total entity count

2. **ID-Based Pagination Setup**:
   - **Batch Size**: 16384 records per batch (optimized size)
   - **Pagination Method**: ID-based thay v√¨ offset-based ƒë·ªÉ avoid offset limitations
   - **Starting Point**: Begin v·ªõi empty last_id

3. **Progressive Loading Loop**:
   ```python
   while True:
       if last_id:
           expr = f'id_sanpham > "{last_id}"'  # Query records after last_id
       else:
           expr = ""  # First batch - get all
       
       batch_results = collection.query(expr=expr, limit=batch_size)
       if not batch_results: break  # No more data
       
       # Sort batch by ID to ensure order
       batch_results.sort(key=lambda x: x.get('id_sanpham', ''))
       all_results.extend(batch_results)
       last_id = batch_results[-1].get('id_sanpham', '')  # Update for next batch
   ```

4. **Progress Tracking**:
   - **Visual Progress Bar**: Real-time progress indication
   - **Status Updates**: Batch-by-batch status messages
   - **Memory Monitoring**: Track loaded record count
   - **Performance Metrics**: Batch timing v√† throughput

5. **Error Handling**:
   - **Batch-level Recovery**: Continue on individual batch failures
   - **Timeout Handling**: Handle connection timeouts gracefully
   - **Memory Management**: Efficient memory usage cho large datasets

6. **Output Fields**: Load comprehensive fields:
   - id_sanpham, platform, description, metadata
   - date, like, comment, share, name_store

##### `@st.cache_data(ttl=7200) load_collection_data_with_pagination()`
**Ch·ª©c nƒÉng**: **ALTERNATIVE PAGINATION LOADER** - Backup loading method
**Logic**:
- Similar to main loader but v·ªõi different error handling strategy
- More aggressive continuation on errors
- Simplified progress tracking
- Used as fallback when main loader has issues

#### **COLLECTION INFORMATION**:

##### `@st.cache_data(ttl=1800) check_collection_exists(collection_name)`
**Ch·ª©c nƒÉng**: **CACHED EXISTENCE CHECK** - Check collection existence v·ªõi caching
**Logic**: Simple cached wrapper around utility.has_collection()

##### `@st.cache_data(ttl=900) get_collection_info()`
**Ch·ª©c nƒÉng**: **COMPREHENSIVE COLLECTION STATS** - Get detailed collection information
**Logic**:
1. **Basic Statistics**:
   - Total entity count
   - Collection name v√† status
2. **Pagination Estimates**:
   - Batch size configuration
   - Estimated number of batches
   - Expected loading time
3. **Performance Testing**:
   - Sample query execution time
   - Performance benchmarks
4. **Method Information**:
   - Pagination method details (ID-based unlimited)
   - Configuration parameters

#### **METADATA PROCESSING WITH CACHING**:

##### `@st.cache_data(ttl=3600) parse_metadata_cached(data_hash, data)`
**Ch·ª©c nƒÉng**: **HASH-BASED METADATA CACHING** - Cache processed metadata by content hash
**Logic**:
- **Content Hashing**: Generate MD5 hash c·ªßa data content
- **Cache Key**: Use data hash as cache key
- **Processing Delegation**: Call parse_metadata_internal()
- **Cache Benefits**: Avoid reprocessing same data multiple times

##### `parse_metadata(data)`
**Ch·ª©c nƒÉng**: **METADATA PARSER ENTRY POINT** - Main metadata parsing function
**Logic**:
1. **Input Validation**: Check data availability
2. **Content Hashing**: Generate hash c·ªßa data cho caching
3. **Cache Lookup**: Check if processed version exists
4. **Processing**: Call cached parser function

##### `parse_metadata_internal(data)`
**Ch·ª©c nƒÉng**: **CORE METADATA PROCESSOR** - Internal parsing logic v·ªõi batch processing
**Logic**:
1. **Batch Processing Setup**:
   - **Batch Size**: 1000 items per batch ƒë·ªÉ optimize memory
   - **Memory Management**: Process data in chunks
2. **Item Processing Loop**:
   ```python
   for item in batch_data:
       try:
           metadata = json.loads(item.get('metadata', '{}'))
           row = {
               'id_sanpham': item.get('id_sanpham', ''),
               'platform': item.get('platform', ''),
               # ... other fields
           }
           # Add metadata fields
           for key, value in metadata.items():
               row[key] = format_metadata_value(value)
           parsed_data.append(row)
       except: continue
   ```
3. **Data Transformation**:
   - **JSON Parsing**: Parse metadata JSON strings
   - **Type Conversion**: Convert engagement numbers to integers
   - **List Formatting**: Format list values th√†nh comma-separated strings
   - **Error Handling**: Skip problematic records v·ªõi warnings

#### **UTILITY FUNCTIONS WITH CACHING**:

##### `@st.cache_data safe_int_convert(value)`
**Ch·ª©c nƒÉng**: **SAFE INTEGER CONVERSION** - Convert values to integers v·ªõi error handling
**Logic**:
- **Type Handling**: Handle int, float, string inputs
- **String Cleaning**: Remove commas v√† spaces
- **Validation**: Check if string is numeric
- **Default Value**: Return 0 on conversion errors

##### `@st.cache_data parse_engagement_string(engagement_str)`
**Ch·ª©c nƒÉng**: **ENGAGEMENT DATA PARSER** - Parse complex engagement data formats
**Logic**:
1. **Format Detection**: Identify engagement string format:
   - **JSON Format**: {"like": 100, "comment": 20, "share": 5}
   - **Dictionary Format**: like: 100, comment: 20, share: 5  
   - **Simple Number**: Single total engagement number
2. **JSON Parsing**: Handle JSON-like strings v·ªõi json.loads()
3. **Regex Extraction**: Use regex to extract numbers after keywords
4. **Fallback Distribution**: Distribute total engagement:
   - 70% likes, 20% comments, 10% shares
5. **Error Recovery**: Return zero values on parsing errors

#### **BATCH PROCESSING WITH CACHING**:

##### `@st.cache_data process_batch_data(data_batch_hash, data_batch)`
**Ch·ª©c nƒÉng**: **CACHED BATCH PROCESSING** - Process data batches v·ªõi caching
**Logic**:
1. **Hash-based Caching**: Use batch content hash cho cache key
2. **Item Processing**: Process each item trong batch:
   - Extract key fields
   - Calculate engagement scores
   - Add processing timestamps
3. **Error Isolation**: Handle individual item errors without affecting batch

##### `calculate_engagement_score(item)`
**Ch·ª©c nƒÉng**: **ENGAGEMENT SCORE CALCULATION** - Calculate weighted engagement score
**Logic**:
- **Weighted Formula**: likes + comments*5 + shares*10
- **Reasoning**: Comments v√† shares have higher engagement value
- **Safe Conversion**: Use safe_int_convert cho all inputs

#### **CACHE MANAGEMENT**:

##### `clear_data_cache()`
**Ch·ª©c nƒÉng**: **CACHE CLEARING** - Clear all data-related caches
**Logic**: Call st.cache_data.clear() v√† provide user feedback

##### `get_cache_stats()`
**Ch·ª©c nƒÉng**: **CACHE STATISTICS** - Get cache performance information
**Logic**: Return available cache statistics (limited by Streamlit version)

##### `@st.cache_data(ttl=300) health_check()`
**Ch·ª©c nƒÉng**: **SYSTEM HEALTH MONITORING** - Check system health v·ªõi caching
**Logic**:
1. **Connection Test**: Test Milvus connection
2. **Collection Test**: Verify collection accessibility
3. **Information Gathering**: Get collection info if available
4. **Status Assessment**: Determine overall system health
5. **Timestamp**: Add health check timestamp
6. **Error Handling**: Provide detailed error information

---

## üîÑ LU·ªíNG X·ª¨ L√ù CH√çNH

### 1. Query Processing Flow:
```
User Query ‚Üí Query Classifier ‚Üí [Smart Search | Traditional Analysis]
```

### 2. Smart Search Flow:
```
Query + Image ‚Üí Determine Search Type ‚Üí Extract Filters ‚Üí Execute Search ‚Üí Results
```

### 3. Filter Extraction Flow:
```
User Query ‚Üí AI Analysis ‚Üí JSON Extraction ‚Üí Validation ‚Üí Clean Filters
```

### 4. Database Integration Flow:
```
Search Tools ‚Üí Milvus Manager ‚Üí Vector Database ‚Üí Processed Results
```

### 5. Data Loading Flow:
```
Collection ‚Üí ID-based Pagination ‚Üí Batch Processing ‚Üí Cached Results ‚Üí DataFrame
```

---

## üéØ ƒêI·ªÇM M·∫†NH C·ª¶A H·ªÜ TH·ªêNG

### 1. Flexible Filter Recognition:
- Kh√¥ng c·∫ßn predefined mappings
- AI t·ª± ƒë·ªông nh·∫≠n di·ªán filters t·ª´ natural language
- Support c·∫£ ti·∫øng Vi·ªát v√† ti·∫øng Anh

### 2. Multi-modal Search:
- Text-to-text, text-to-image, image-to-image
- URL image support
- Multimodal search combining text + image

### 3. Intelligent Routing:
- Automatic query classification
- Context-aware processing
- Efficient resource utilization

### 4. Robust Error Handling:
- Graceful degradation
- Clear error messages
- Fallback mechanisms

### 5. Advanced Search Processing:
- AI-powered query enhancement
- Multi-strategy search execution
- Intelligent result scoring v√† ranking

### 6. High-Performance Data Management:
- ID-based pagination (unlimited scaling)
- Comprehensive caching strategies
- Batch processing optimization
- Real-time progress tracking

### 7. Scalable Vector Database Integration:
- Efficient vector similarity search
- Multi-modal embeddings
- Advanced filtering capabilities
- Batch operations support

---

## ‚ö†Ô∏è ƒêI·ªÇM C·∫¶N L∆ØU √ù

### 1. Time Keywords Detection:
- Function `_contains_time_keywords()` r·∫•t quan tr·ªçng
- Prevent false positive date extraction
- C·∫ßn maintain comprehensive keyword list

### 2. Filter Validation:
- Date format ph·∫£i DD/MM/YYYY
- Validation logic trong `_is_valid_date_string()`
- AI response parsing c·∫ßn robust error handling

### 3. Search Type Logic:
- 8 lo·∫°i search type kh√°c nhau
- Priority order trong `determine_search_type()`
- Image URL vs base64 handling

### 4. API Dependencies:
- OpenAI API key management
- Vision model limits
- Milvus database connection

### 5. Memory Management:
- Large dataset loading considerations  
- Batch processing memory usage
- Cache size limitations
- Progress tracking overhead

### 6. Database Performance:
- ID-based pagination benefits v√† limitations
- Vector search performance tuning
- Filter expression optimization
- Concurrent access handling

---

## üöÄ H∆Ø·ªöNG D·∫™N DEPLOYMENT

### Environment Setup:
```bash
pip install langchain langgraph openai
pip install pymilvus streamlit pandas pillow
# C·∫ßn setup Milvus database
# Configure OpenAI API key
```

### Key Configuration:
- API keys trong Config.settings
- Milvus database connection string (localhost:19530)
- Model names v√† parameters
- Streamlit caching configuration

### Database Setup:
- Milvus server installation v√† configuration
- Collection schema setup
- Index optimization cho vector fields
- Data migration v√† initial loading

---

## üìû TH√îNG TIN H·ªñ TR·ª¢

### Architecture Decisions:
- LangGraph ƒë·ªÉ orchestrate workflow
- AI-based filter extraction thay v√¨ rule-based
- Multi-modal support cho flexibility
- ID-based pagination cho unlimited scaling
- Comprehensive caching strategies
- Advanced search processing pipeline

### Performance Considerations:
- Temperature settings cho different tasks
- Caching strategies cho optimal performance
- Database query optimization
- Memory management cho large datasets
- Batch processing efficiency
- Vector search performance tuning

### Maintenance Notes:
- Regular cache clearing might be needed
- Monitor Milvus database performance
- Update search query processors theo user feedback
- API rate limit monitoring
- Error log analysis cho system health

---

**L∆∞u √Ω**: ƒê√¢y l√† h·ªá th·ªëng AI ph·ª©c t·∫°p v·ªõi nhi·ªÅu integration points v√† advanced features. C·∫ßn hi·ªÉu r√µ logic c·ªßa t·ª´ng component ƒë·ªÉ maintain v√† extend hi·ªáu qu·∫£. ƒê·∫∑c bi·ªát ch√∫ √Ω ƒë·∫øn caching strategies v√† database performance optimization.
